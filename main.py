import io
import unicodedata
from pathlib import Path

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st


# =========================
# App Config
# =========================
st.set_page_config(page_title="ğŸŒ± ê·¹ì§€ì‹ë¬¼ ìµœì  EC ë†ë„ ì—°êµ¬", layout="wide")

# Korean font (Streamlit UI)
st.markdown(
    """
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap');
html, body, [class*="css"] {
    font-family: 'Noto Sans KR', 'Malgun Gothic', sans-serif;
}
</style>
""",
    unsafe_allow_html=True,
)

PLOTLY_FONT = "Malgun Gothic, Apple SD Gothic Neo, Noto Sans KR, sans-serif"

SCHOOLS = ["ì†¡ë„ê³ ", "í•˜ëŠ˜ê³ ", "ì•„ë¼ê³ ", "ë™ì‚°ê³ "]

TARGET_EC = {
    "ì†¡ë„ê³ ": 1.0,
    "í•˜ëŠ˜ê³ ": 2.0,  # ìµœì (ê°€ì •/ê¸°ëŒ€)
    "ì•„ë¼ê³ ": 4.0,
    "ë™ì‚°ê³ ": 8.0,
}

SCHOOL_COLOR = {
    "ì†¡ë„ê³ ": "#1f77b4",
    "í•˜ëŠ˜ê³ ": "#ff7f0e",
    "ì•„ë¼ê³ ": "#2ca02c",
    "ë™ì‚°ê³ ": "#d62728",
}


# =========================
# Helpers (NFC/NFD-safe)
# =========================
def _norm_variants(text: str) -> set[str]:
    return {
        unicodedata.normalize("NFC", text),
        unicodedata.normalize("NFD", text),
    }


def _simplify(text: str) -> str:
    """
    íŒŒì¼ëª… ë§¤ì¹­ ì‹¤íŒ¨ ë°©ì§€:
    - NFC/NFD ì •ê·œí™”
    - ê³µë°±/ì–¸ë”ë°”/í•˜ì´í”ˆ/ì /ê´„í˜¸ ë“± êµ¬ë¶„ì ì œê±°
    """
    t = unicodedata.normalize("NFC", str(text))
    for ch in [" ", "_", "-", ".", "(", ")", "[", "]", "{", "}", "ã€€"]:
        t = t.replace(ch, "")
    return t


def _contains_all_tokens(name: str, tokens: list[str]) -> bool:
    """
    NFC/NFD + êµ¬ë¶„ì ì œê±° ê¸°ë°˜ìœ¼ë¡œ í† í° í¬í•¨ ì—¬ë¶€ íŒì •
    """
    name_variants = {_simplify(v) for v in _norm_variants(name)}
    token_variants_list = [{_simplify(v) for v in _norm_variants(t)} for t in tokens]

    for token_variants in token_variants_list:
        if not any(any(tok in nm for tok in token_variants) for nm in name_variants):
            return False
    return True


def _pick_file_by_tokens(data_dir: Path, required_tokens: list[str], allowed_suffixes: set[str]) -> Path | None:
    """
    Must use Path.iterdir().
    No f-string filename composition.
    No glob-only approach.
    NFC/NFD bidirectional check.
    """
    if not data_dir.exists():
        return None

    for p in data_dir.iterdir():
        if not p.is_file():
            continue
        if p.suffix.lower() not in allowed_suffixes:
            continue
        if _contains_all_tokens(p.name, required_tokens):
            return p
    return None


def _pick_csv_for_school(data_dir: Path, school: str) -> Path | None:
    # tokens: í•™êµëª… + í™˜ê²½ë°ì´í„° + .csv
    return _pick_file_by_tokens(
        data_dir=data_dir,
        required_tokens=[school, "í™˜ê²½ë°ì´í„°"],
        allowed_suffixes={".csv"},
    )


def _pick_growth_xlsx(data_dir: Path) -> Path | None:
    # tokens: ìƒìœ¡ê²°ê³¼ë°ì´í„° + .xlsx
    return _pick_file_by_tokens(
        data_dir=data_dir,
        required_tokens=["ìƒìœ¡ê²°ê³¼ë°ì´í„°"],
        allowed_suffixes={".xlsx"},
    )


def _resolve_data_dir() -> Path:
    """
    Streamlit Cloud/ë¡œì»¬ ëª¨ë‘ ì•ˆì „:
    - main.py ìœ„ì¹˜ ê¸°ì¤€
    - í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ê¸°ì¤€
    - ìƒìœ„ í´ë”ë¥¼ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ë©° data íƒìƒ‰
    """
    candidates = []

    # 1) main.py ê¸°ì¤€
    try:
        here = Path(__file__).resolve().parent
        candidates.append(here / "data")
        candidates.append(here.parent / "data")
    except Exception:
        pass

    # 2) cwd ê¸°ì¤€
    candidates.append(Path.cwd() / "data")

    # 3) ìƒìœ„ë¡œ ì˜¬ë¼ê°€ë©° data íƒìƒ‰ (ìµœëŒ€ 4ë‹¨ê³„)
    p = Path.cwd().resolve()
    for _ in range(4):
        candidates.append(p / "data")
        p = p.parent

    for c in candidates:
        if c.exists() and c.is_dir():
            return c

    # ì—†ìœ¼ë©´ ê¸°ë³¸ê°’(ì—ëŸ¬ ë©”ì‹œì§€ìš©)
    return Path.cwd() / "data"


# =========================
# Data Loading
# =========================
def _standardize_env_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]

    colmap = {}
    for c in df.columns:
        cl = str(c).strip().lower()
        if cl in {"time", "datetime", "date", "timestamp"}:
            colmap[c] = "time"
        elif "temp" in cl or "temperature" in cl or "ì˜¨ë„" in cl:
            colmap[c] = "temperature"
        elif "humid" in cl or "humidity" in cl or "ìŠµë„" in cl:
            colmap[c] = "humidity"
        elif cl == "ph" or "ì‚°ë„" in cl:
            colmap[c] = "ph"
        elif cl == "ec" or "ì „ê¸°ì „ë„" in cl:
            colmap[c] = "ec"

    df = df.rename(columns=colmap)

    required = {"time", "temperature", "humidity", "ph", "ec"}
    missing = required - set(df.columns)
    if missing:
        raise ValueError(f"í™˜ê²½ ë°ì´í„° í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {sorted(missing)}")

    df["time"] = pd.to_datetime(df["time"], errors="coerce")
    df = df.dropna(subset=["time"])
    for c in ["temperature", "humidity", "ph", "ec"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")

    return df


def _standardize_growth_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]

    def find_col(keys: list[str]) -> str | None:
        for c in df.columns:
            for k in keys:
                if k in str(c).replace(" ", ""):
                    return c
        return None

    col_id = find_col(["ê°œì²´ë²ˆí˜¸", "ê°œì²´", "ë²ˆí˜¸"])
    col_leaf = find_col(["ììˆ˜", "ììˆ˜(ì¥)", "ì"])
    col_shoot = find_col(["ì§€ìƒë¶€ê¸¸ì´", "ì§€ìƒë¶€", "ì§€ìƒë¶€ê¸¸ì´(mm)"])
    col_root = find_col(["ì§€í•˜ë¶€ê¸¸ì´", "ì§€í•˜ë¶€", "ì§€í•˜ë¶€ê¸¸ì´(mm)"])
    col_w = find_col(["ìƒì¤‘ëŸ‰", "ìƒì¤‘ëŸ‰(g)", "ì¤‘ëŸ‰", "ë¬´ê²Œ"])

    mapping = {}
    if col_id:
        mapping[col_id] = "id"
    if col_leaf:
        mapping[col_leaf] = "leaf_count"
    if col_shoot:
        mapping[col_shoot] = "shoot_len_mm"
    if col_root:
        mapping[col_root] = "root_len_mm"
    if col_w:
        mapping[col_w] = "fresh_weight_g"

    df = df.rename(columns=mapping)

    required = {"id", "leaf_count", "shoot_len_mm", "fresh_weight_g"}
    missing = required - set(df.columns)
    if missing:
        raise ValueError(f"ìƒìœ¡ ê²°ê³¼ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½/ì¸ì‹ ì‹¤íŒ¨: {sorted(missing)}")

    for c in ["leaf_count", "shoot_len_mm", "root_len_mm", "fresh_weight_g"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")

    return df


@st.cache_data(show_spinner=False)
def load_environment_data(data_dir_str: str) -> dict[str, pd.DataFrame]:
    data_dir = Path(data_dir_str)
    env: dict[str, pd.DataFrame] = {}

    for school in SCHOOLS:
        p = _pick_csv_for_school(data_dir, school)
        if p is None:
            env[school] = pd.DataFrame()
            continue

        last_err = None
        for enc in ["utf-8-sig", "utf-8", "cp949", "euc-kr"]:
            try:
                df = pd.read_csv(p, encoding=enc)
                df = _standardize_env_df(df)
                df["school"] = school
                env[school] = df
                last_err = None
                break
            except Exception as e:
                last_err = e

        if last_err is not None:
            env[school] = pd.DataFrame()

    return env


@st.cache_data(show_spinner=False)
def load_growth_data(data_dir_str: str) -> dict[str, pd.DataFrame]:
    data_dir = Path(data_dir_str)
    xlsx_path = _pick_growth_xlsx(data_dir)
    if xlsx_path is None:
        return {}

    xls = pd.ExcelFile(xlsx_path, engine="openpyxl")
    sheets = xls.sheet_names

    out: dict[str, pd.DataFrame] = {}
    for sheet in sheets:
        raw = pd.read_excel(xlsx_path, sheet_name=sheet, engine="openpyxl")
        if raw is None or raw.empty:
            continue

        matched_school = None
        for s in SCHOOLS:
            if _contains_all_tokens(sheet, [s]):
                matched_school = s
                break

        label = matched_school if matched_school else sheet

        df = _standardize_growth_df(raw)
        df["school"] = label
        out[label] = df

    return out


def _safe_concat(dfs: list[pd.DataFrame]) -> pd.DataFrame:
    dfs2 = [d for d in dfs if d is not None and not d.empty]
    if not dfs2:
        return pd.DataFrame()
    return pd.concat(dfs2, ignore_index=True)


def _plotly_layout(fig: go.Figure, title: str | None = None) -> go.Figure:
    fig.update_layout(
        title=title,
        font=dict(family=PLOTLY_FONT),
        legend_title_text="",
        margin=dict(l=20, r=20, t=60 if title else 30, b=20),
    )
    return fig


# =========================
# Load Data
# =========================
DATA_DIR = _resolve_data_dir()

# ë””ë²„ê·¸: ì‹¤ì œ data í´ë”ê°€ ì–´ë””ë¡œ ì¡í˜”ëŠ”ì§€ + ë‚´ë¶€ íŒŒì¼ í‘œì‹œ
st.caption(f"ğŸ“ data í´ë” ê²½ë¡œ: {DATA_DIR}")
if not DATA_DIR.exists():
    st.error("data/ í´ë”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë¦¬í¬ì§€í† ë¦¬ ë£¨íŠ¸ì— data í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
else:
    files = [p.name for p in DATA_DIR.iterdir() if p.is_file()]
    st.caption(f"ğŸ“„ íƒì§€ëœ íŒŒì¼: {', '.join(files) if files else '(ì—†ìŒ)'}")

with st.spinner("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
    env_by_school = load_environment_data(str(DATA_DIR))
    growth_by_school = load_growth_data(str(DATA_DIR))

env_all = _safe_concat([env_by_school.get(s, pd.DataFrame()) for s in SCHOOLS])
growth_all = _safe_concat([growth_by_school.get(k, pd.DataFrame()) for k in growth_by_school.keys()])

if env_all.empty:
    st.error("í™˜ê²½ ë°ì´í„°(CSV)ë¥¼ ì°¾ì§€ ëª»í–ˆê±°ë‚˜ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. data/ í´ë”ì™€ íŒŒì¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”.")
if not growth_by_school:
    st.error("ìƒìœ¡ ê²°ê³¼ ë°ì´í„°(XLSX)ë¥¼ ì°¾ì§€ ëª»í–ˆê±°ë‚˜ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. data/ í´ë”ì™€ íŒŒì¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”.")


# =========================
# Sidebar
# =========================
st.title("ğŸŒ± ê·¹ì§€ì‹ë¬¼ ìµœì  EC ë†ë„ ì—°êµ¬")

sel_school = st.sidebar.selectbox("í•™êµ ì„ íƒ", ["ì „ì²´"] + SCHOOLS, index=0)
selected_schools = SCHOOLS if sel_school == "ì „ì²´" else [sel_school]


def get_selected_env() -> pd.DataFrame:
    return _safe_concat([env_by_school.get(s, pd.DataFrame()) for s in selected_schools])


def get_selected_growth() -> pd.DataFrame:
    dfs = []
    for s in selected_schools:
        if s in growth_by_school:
            dfs.append(growth_by_school[s])
    return _safe_concat(dfs)


# =========================
# Tabs
# =========================
tab1, tab2, tab3 = st.tabs(["ğŸ“– ì‹¤í—˜ ê°œìš”", "ğŸŒ¡ï¸ í™˜ê²½ ë°ì´í„°", "ğŸ“Š ìƒìœ¡ ê²°ê³¼"])

# -------------------------
# Tab 1: Overview
# -------------------------
with tab1:
    st.subheader("ì—°êµ¬ ë°°ê²½ ë° ëª©ì ")
    st.write(
        """
ë³¸ ëŒ€ì‹œë³´ë“œëŠ” 4ê°œ í•™êµì—ì„œ ì„œë¡œ ë‹¤ë¥¸ EC(ì „ê¸°ì „ë„ë„) ì¡°ê±´ìœ¼ë¡œ ê·¹ì§€ì‹ë¬¼ì„ ì¬ë°°í•œ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬,
(1) í•™êµë³„ í™˜ê²½(ì˜¨ë„/ìŠµë„/pH/EC) íŠ¹ì„±ì„ ë¹„êµí•˜ê³ , (2) EC ì¡°ê±´ë³„ ìƒìœ¡(ìƒì¤‘ëŸ‰/ì ìˆ˜/ê¸¸ì´)ì„ ì •ëŸ‰ ë¹„êµí•˜ì—¬,
(3) ìµœì  EC ë†ë„ë¥¼ ë„ì¶œí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.
"""
    )

    rows = []
    for s in SCHOOLS:
        n = int(growth_by_school.get(s, pd.DataFrame()).shape[0]) if s in growth_by_school else 0
        rows.append({"í•™êµëª…": s, "EC ëª©í‘œ": TARGET_EC.get(s, None), "ê°œì²´ìˆ˜": n, "ìƒ‰ìƒ": SCHOOL_COLOR.get(s, "#999999")})
    cond_df = pd.DataFrame(rows)

    st.markdown("#### í•™êµë³„ EC ì¡°ê±´")
    st.dataframe(cond_df, use_container_width=True, hide_index=True)

    env_sel = get_selected_env()
    growth_sel = get_selected_growth()

    total_n = int(growth_sel.shape[0]) if not growth_sel.empty else 0
    avg_temp = float(env_sel["temperature"].mean()) if not env_sel.empty else float("nan")
    avg_hum = float(env_sel["humidity"].mean()) if not env_sel.empty else float("nan")

    best_ec = None
    if not growth_all.empty:
        tmp = growth_all.copy()
        tmp = tmp[tmp["school"].isin(SCHOOLS)]
        if not tmp.empty and "fresh_weight_g" in tmp.columns:
            mean_w = tmp.groupby("school", as_index=False)["fresh_weight_g"].mean()
            mean_w["target_ec"] = mean_w["school"].map(TARGET_EC)
            mean_w = mean_w.dropna(subset=["target_ec"])
            if not mean_w.empty:
                best_row = mean_w.sort_values("fresh_weight_g", ascending=False).iloc[0]
                best_ec = float(best_row["target_ec"])

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ì´ ê°œì²´ìˆ˜", f"{total_n:,}")
    c2.metric("í‰ê·  ì˜¨ë„(Â°C)", "-" if env_sel.empty else f"{avg_temp:.2f}")
    c3.metric("í‰ê·  ìŠµë„(%)", "-" if env_sel.empty else f"{avg_hum:.2f}")
    c4.metric("ë„ì¶œëœ ìµœì  EC", "-" if best_ec is None else f"{best_ec:.1f}")

# -------------------------
# Tab 2: Environment
# -------------------------
with tab2:
    st.subheader("í•™êµë³„ í™˜ê²½ ë°ì´í„° ë¹„êµ")

    env_sel = get_selected_env()

    if env_all.empty:
        st.error("í™˜ê²½ ë°ì´í„°ê°€ ì—†ì–´ ì‹œê°í™”ë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        env_avg = (
            env_all.groupby("school", as_index=False)[["temperature", "humidity", "ph", "ec"]]
            .mean()
            .sort_values("school")
        )
        env_avg["target_ec"] = env_avg["school"].map(TARGET_EC)

        fig = make_subplots(rows=2, cols=2, subplot_titles=("í‰ê·  ì˜¨ë„", "í‰ê·  ìŠµë„", "í‰ê·  pH", "ëª©í‘œ EC vs ì‹¤ì¸¡ EC(í‰ê· )"))

        fig.add_trace(go.Bar(x=env_avg["school"], y=env_avg["temperature"], name="ì˜¨ë„"), row=1, col=1)
        fig.add_trace(go.Bar(x=env_avg["school"], y=env_avg["humidity"], name="ìŠµë„"), row=1, col=2)
        fig.add_trace(go.Bar(x=env_avg["school"], y=env_avg["ph"], name="pH"), row=2, col=1)
        fig.add_trace(go.Bar(x=env_avg["school"], y=env_avg["target_ec"], name="ëª©í‘œ EC"), row=2, col=2)
        fig.add_trace(go.Bar(x=env_avg["school"], y=env_avg["ec"], name="ì‹¤ì¸¡ EC(í‰ê· )"), row=2, col=2)

        fig.update_layout(barmode="group")
        fig = _plotly_layout(fig, "í•™êµë³„ í™˜ê²½ í‰ê·  ë¹„êµ(2x2)")
        st.plotly_chart(fig, use_container_width=True)

        st.markdown("#### ì„ íƒí•œ í•™êµ ì‹œê³„ì—´")

        def _timeseries_fig(metric: str, title: str, add_target_ec: bool = False) -> go.Figure:
            base = env_all if sel_school == "ì „ì²´" else env_sel
            if base.empty:
                return go.Figure()

            fig_ts = go.Figure()
            for s in (SCHOOLS if sel_school == "ì „ì²´" else [sel_school]):
                d = env_by_school.get(s, pd.DataFrame())
                if d is None or d.empty:
                    continue
                fig_ts.add_trace(go.Scatter(x=d["time"], y=d[metric], mode="lines", name=s))

            if add_target_ec and sel_school != "ì „ì²´":
                t = TARGET_EC.get(sel_school, None)
                if t is not None:
                    fig_ts.add_hline(y=float(t), line_dash="dash", annotation_text="ëª©í‘œ EC", annotation_position="top left")

            fig_ts = _plotly_layout(fig_ts, title)
            fig_ts.update_xaxes(title_text="time")
            fig_ts.update_yaxes(title_text=metric)
            return fig_ts

        colA, colB, colC = st.columns(3)
        with colA:
            fig_t = _timeseries_fig("temperature", "ì˜¨ë„ ë³€í™”")
            if fig_t.data:
                st.plotly_chart(fig_t, use_container_width=True)
            else:
                st.error("ì„ íƒ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” ì˜¨ë„ ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        with colB:
            fig_h = _timeseries_fig("humidity", "ìŠµë„ ë³€í™”")
            if fig_h.data:
                st.plotly_chart(fig_h, use_container_width=True)
            else:
                st.error("ì„ íƒ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” ìŠµë„ ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        with colC:
            fig_e = _timeseries_fig("ec", "EC ë³€í™” (ëª©í‘œ EC ìˆ˜í‰ì„  í¬í•¨)", add_target_ec=True)
            if fig_e.data:
                st.plotly_chart(fig_e, use_container_width=True)
            else:
                st.error("ì„ íƒ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” EC ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        with st.expander("í™˜ê²½ ë°ì´í„° ì›ë³¸ í…Œì´ë¸” + CSV ë‹¤ìš´ë¡œë“œ"):
            show_df = env_sel if sel_school != "ì „ì²´" else env_all
            if show_df.empty:
                st.error("í‘œì‹œí•  í™˜ê²½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.dataframe(show_df.sort_values(["school", "time"]), use_container_width=True, hide_index=True)
                csv_bytes = show_df.to_csv(index=False).encode("utf-8-sig")
                st.download_button("CSV ë‹¤ìš´ë¡œë“œ", data=csv_bytes, file_name="í™˜ê²½ë°ì´í„°_ì„ íƒë²”ìœ„.csv", mime="text/csv")

# -------------------------
# Tab 3: Growth
# -------------------------
with tab3:
    st.subheader("ECë³„ ìƒìœ¡ ê²°ê³¼ ë¹„êµ")

    if growth_all.empty:
        st.error("ìƒìœ¡ ê²°ê³¼ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        g = growth_all.copy()
        g = g[g["school"].isin(SCHOOLS)].copy()

        if g.empty:
            st.error("ìƒìœ¡ ê²°ê³¼ì—ì„œ í•™êµ ë§¤ì¹­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. XLSX ì‹œíŠ¸ëª…ì— í•™êµëª…ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        else:
            g["target_ec"] = g["school"].map(TARGET_EC)

            summary = (
                g.groupby(["school", "target_ec"], as_index=False)
                .agg(
                    mean_weight=("fresh_weight_g", "mean"),
                    mean_leaf=("leaf_count", "mean"),
                    mean_shoot=("shoot_len_mm", "mean"),
                    count=("id", "count"),
                )
                .sort_values("target_ec")
            )

            best = summary.sort_values("mean_weight", ascending=False).iloc[0]
            best_school = str(best["school"])
            best_ec_val = float(best["target_ec"])
            best_w = float(best["mean_weight"])

            note = "â­ ìµœëŒ“ê°’" if best_school == "í•˜ëŠ˜ê³ " else "ìµœëŒ“ê°’"
            st.markdown("### ğŸ¥‡ í•µì‹¬ ê²°ê³¼")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("ìµœëŒ€ í‰ê·  ìƒì¤‘ëŸ‰(EC)", f"{best_w:.3f} g", delta=f"{best_ec_val:.1f}")
            c2.metric("ìµœëŒ€ í‰ê·  ìƒì¤‘ëŸ‰ í•™êµ", best_school, delta=note)
            exp_opt = TARGET_EC.get("í•˜ëŠ˜ê³ ", None)
            c3.metric("ê°€ì •/ì¡°ê±´ìƒ ìµœì  EC(í•˜ëŠ˜ê³ )", "-" if exp_opt is None else f"{exp_opt:.1f}")
            c4.metric("ë¶„ì„ í¬í•¨ ê°œì²´ìˆ˜(4ê°œêµ í•©)", f"{int(g.shape[0]):,}")

            fig2 = make_subplots(rows=2, cols=2, subplot_titles=("í‰ê·  ìƒì¤‘ëŸ‰(â­)", "í‰ê·  ì ìˆ˜", "í‰ê·  ì§€ìƒë¶€ ê¸¸ì´(mm)", "ê°œì²´ìˆ˜ ë¹„êµ"))

            fig2.add_trace(go.Bar(x=summary["target_ec"], y=summary["mean_weight"], name="í‰ê·  ìƒì¤‘ëŸ‰"), row=1, col=1)
            fig2.add_trace(go.Bar(x=summary["target_ec"], y=summary["mean_leaf"], name="í‰ê·  ì ìˆ˜"), row=1, col=2)
            fig2.add_trace(go.Bar(x=summary["target_ec"], y=summary["mean_shoot"], name="í‰ê·  ì§€ìƒë¶€ ê¸¸ì´"), row=2, col=1)
            fig2.add_trace(go.Bar(x=summary["target_ec"], y=summary["count"], name="ê°œì²´ìˆ˜"), row=2, col=2)

            fig2.add_vline(x=best_ec_val, line_dash="dash", annotation_text="ìµœì (í‰ê·  ìƒì¤‘ëŸ‰ ìµœëŒ€)", annotation_position="top left", row=1, col=1)

            fig2.update_layout(barmode="group")
            fig2 = _plotly_layout(fig2, "ECë³„ ìƒìœ¡ ì§€í‘œ ë¹„êµ(2x2)")
            st.plotly_chart(fig2, use_container_width=True)

            st.markdown("#### í•™êµë³„ ìƒì¤‘ëŸ‰ ë¶„í¬")
            fig_box = px.box(g, x="school", y="fresh_weight_g", points="outliers", title="í•™êµë³„ ìƒì¤‘ëŸ‰ ë¶„í¬(ë°•ìŠ¤í”Œë¡¯)")
            fig_box = _plotly_layout(fig_box)
            st.plotly_chart(fig_box, use_container_width=True)

            st.markdown("#### ìƒê´€ê´€ê³„ ë¶„ì„")
            cc1, cc2 = st.columns(2)

            with cc1:
                fig_sc1 = px.scatter(g, x="leaf_count", y="fresh_weight_g", color="school", title="ì ìˆ˜ vs ìƒì¤‘ëŸ‰")
                fig_sc1 = _plotly_layout(fig_sc1)
                st.plotly_chart(fig_sc1, use_container_width=True)

            with cc2:
                fig_sc2 = px.scatter(g, x="shoot_len_mm", y="fresh_weight_g", color="school", title="ì§€ìƒë¶€ ê¸¸ì´ vs ìƒì¤‘ëŸ‰")
                fig_sc2 = _plotly_layout(fig_sc2)
                st.plotly_chart(fig_sc2, use_container_width=True)

            with st.expander("í•™êµë³„ ìƒìœ¡ ë°ì´í„° ì›ë³¸ + XLSX ë‹¤ìš´ë¡œë“œ"):
                g_sel = get_selected_growth()
                if sel_school == "ì „ì²´":
                    show_g = g.sort_values(["school", "id"])
                else:
                    show_g = g_sel.sort_values(["school", "id"]) if not g_sel.empty else pd.DataFrame()

                if show_g.empty:
                    st.error("í‘œì‹œí•  ìƒìœ¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ì„ íƒ í•™êµì˜ ì‹œíŠ¸ ë§¤ì¹­/ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”)")
                else:
                    st.dataframe(show_g, use_container_width=True, hide_index=True)

                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                    if sel_school == "ì „ì²´":
                        for s in SCHOOLS:
                            df_s = g[g["school"] == s].copy()
                            if not df_s.empty:
                                df_s.to_excel(writer, index=False, sheet_name=s)
                    else:
                        show_g.to_excel(writer, index=False, sheet_name=sel_school)

                buffer.seek(0)
                st.download_button(
                    "XLSX ë‹¤ìš´ë¡œë“œ",
                    data=buffer,
                    file_name="ìƒìœ¡ê²°ê³¼_ì„ íƒë²”ìœ„.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                )
