import io
import unicodedata
from pathlib import Path

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st


# =========================
# App Config
# =========================
st.set_page_config(
    page_title="ğŸŒ± ê·¹ì§€ì‹ë¬¼ ìµœì  EC ë†ë„ ì—°êµ¬",
    layout="wide",
)

# Korean font (Streamlit UI)
st.markdown(
    """
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap');
html, body, [class*="css"] {
    font-family: 'Noto Sans KR', 'Malgun Gothic', sans-serif;
}
</style>
""",
    unsafe_allow_html=True,
)

PLOTLY_FONT = "Malgun Gothic, Apple SD Gothic Neo, Noto Sans KR, sans-serif"

SCHOOLS = ["ì†¡ë„ê³ ", "í•˜ëŠ˜ê³ ", "ì•„ë¼ê³ ", "ë™ì‚°ê³ "]

TARGET_EC = {
    "ì†¡ë„ê³ ": 1.0,
    "í•˜ëŠ˜ê³ ": 2.0,  # ìµœì (ê°€ì •/ê¸°ëŒ€)
    "ì•„ë¼ê³ ": 4.0,
    "ë™ì‚°ê³ ": 8.0,
}

SCHOOL_COLOR = {
    "ì†¡ë„ê³ ": "#1f77b4",
    "í•˜ëŠ˜ê³ ": "#ff7f0e",
    "ì•„ë¼ê³ ": "#2ca02c",
    "ë™ì‚°ê³ ": "#d62728",
}


# =========================
# Helpers (NFC/NFD-safe)
# =========================
def _norm_variants(text: str) -> set[str]:
    """Return both NFC/NFD variants for robust comparison."""
    return {
        unicodedata.normalize("NFC", text),
        unicodedata.normalize("NFD", text),
    }


def _contains_all_tokens(name: str, tokens: list[str]) -> bool:
    """Check if normalized variants of name contain all tokens (also normalized both ways)."""
    name_variants = _norm_variants(name)
    token_sets = [_norm_variants(t) for t in tokens]
    for tset in token_sets:
        if not any(any(t in nv for t in tset) for nv in name_variants):
            return False
    return True


def _pick_file_by_tokens(data_dir: Path, required_tokens: list[str], allowed_suffixes: set[str]) -> Path | None:
    """
    Must use Path.iterdir().
    No f-string filename composition.
    No glob-only approach.
    NFC/NFD bidirectional check.
    """
    if not data_dir.exists():
        return None

    for p in data_dir.iterdir():
        if not p.is_file():
            continue
        if p.suffix.lower() not in allowed_suffixes:
            continue
        if _contains_all_tokens(p.name, required_tokens):
            return p
    return None


def _pick_csv_for_school(data_dir: Path, school: str) -> Path | None:
    # tokens: í•™êµëª… + í™˜ê²½ë°ì´í„° + .csv
    return _pick_file_by_tokens(
        data_dir=data_dir,
        required_tokens=[school, "í™˜ê²½ë°ì´í„°"],
        allowed_suffixes={".csv"},
    )


def _pick_growth_xlsx(data_dir: Path) -> Path | None:
    # tokens: ìƒìœ¡ê²°ê³¼ë°ì´í„° + .xlsx
    return _pick_file_by_tokens(
        data_dir=data_dir,
        required_tokens=["ìƒìœ¡ê²°ê³¼ë°ì´í„°"],
        allowed_suffixes={".xlsx"},
    )


# =========================
# Data Loading
# =========================
def _standardize_env_df(df: pd.DataFrame) -> pd.DataFrame:
    # expected columns: time, temperature, humidity, ph, ec
    # be tolerant: strip spaces, lower
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]

    # attempt to map common variants
    colmap = {}
    for c in df.columns:
        cl = str(c).strip().lower()
        if cl in {"time", "datetime", "date", "timestamp"}:
            colmap[c] = "time"
        elif "temp" in cl or "temperature" in cl or "ì˜¨ë„" in cl:
            colmap[c] = "temperature"
        elif "humid" in cl or "humidity" in cl or "ìŠµë„" in cl:
            colmap[c] = "humidity"
        elif cl == "ph" or "ì‚°ë„" in cl:
            colmap[c] = "ph"
        elif cl == "ec" or "ì „ê¸°ì „ë„" in cl:
            colmap[c] = "ec"
    df = df.rename(columns=colmap)

    required = {"time", "temperature", "humidity", "ph", "ec"}
    missing = required - set(df.columns)
    if missing:
        raise ValueError(f"í™˜ê²½ ë°ì´í„° í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {sorted(missing)}")

    df["time"] = pd.to_datetime(df["time"], errors="coerce")
    df = df.dropna(subset=["time"])
    for c in ["temperature", "humidity", "ph", "ec"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")
    return df


def _standardize_growth_df(df: pd.DataFrame) -> pd.DataFrame:
    """
    expected columns (Korean):
    ê°œì²´ë²ˆí˜¸, ì ìˆ˜(ì¥), ì§€ìƒë¶€ ê¸¸ì´(mm), ì§€í•˜ë¶€ê¸¸ì´(mm), ìƒì¤‘ëŸ‰(g)
    But be robust: match by keyword contains.
    """
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]

    def find_col(keys: list[str]) -> str | None:
        for c in df.columns:
            for k in keys:
                if k in str(c).replace(" ", ""):
                    return c
        return None

    col_id = find_col(["ê°œì²´ë²ˆí˜¸", "ê°œì²´", "ë²ˆí˜¸"])
    col_leaf = find_col(["ììˆ˜", "ììˆ˜(ì¥)", "ì"])
    col_shoot = find_col(["ì§€ìƒë¶€ê¸¸ì´", "ì§€ìƒë¶€", "ì§€ìƒë¶€ê¸¸ì´(mm)"])
    col_root = find_col(["ì§€í•˜ë¶€ê¸¸ì´", "ì§€í•˜ë¶€", "ì§€í•˜ë¶€ê¸¸ì´(mm)"])
    col_w = find_col(["ìƒì¤‘ëŸ‰", "ìƒì¤‘ëŸ‰(g)", "ì¤‘ëŸ‰", "ë¬´ê²Œ"])

    mapping = {}
    if col_id: mapping[col_id] = "id"
    if col_leaf: mapping[col_leaf] = "leaf_count"
    if col_shoot: mapping[col_shoot] = "shoot_len_mm"
    if col_root: mapping[col_root] = "root_len_mm"
    if col_w: mapping[col_w] = "fresh_weight_g"

    df = df.rename(columns=mapping)

    required = {"id", "leaf_count", "shoot_len_mm", "fresh_weight_g"}
    missing = required - set(df.columns)
    if missing:
        raise ValueError(f"ìƒìœ¡ ê²°ê³¼ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½/ì¸ì‹ ì‹¤íŒ¨: {sorted(missing)}")

    # numeric
    for c in ["leaf_count", "shoot_len_mm", "root_len_mm", "fresh_weight_g"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df


@st.cache_data(show_spinner=False)
def load_environment_data(data_dir_str: str) -> dict[str, pd.DataFrame]:
    data_dir = Path(data_dir_str)
    env = {}

    for school in SCHOOLS:
        p = _pick_csv_for_school(data_dir, school)
        if p is None:
            env[school] = pd.DataFrame()
            continue
        df = pd.read_csv(p, encoding="utf-8-sig")
        df = _standardize_env_df(df)
        df["school"] = school
        env[school] = df

    return env


@st.cache_data(show_spinner=False)
def load_growth_data(data_dir_str: str) -> dict[str, pd.DataFrame]:
    data_dir = Path(data_dir_str)
    xlsx_path = _pick_growth_xlsx(data_dir)
    if xlsx_path is None:
        return {}

    # sheet names are NOT hard-coded: read dynamically
    xls = pd.ExcelFile(xlsx_path, engine="openpyxl")
    sheets = xls.sheet_names

    out: dict[str, pd.DataFrame] = {}
    for sheet in sheets:
        raw = pd.read_excel(xlsx_path, sheet_name=sheet, engine="openpyxl")
        if raw is None or raw.empty:
            continue

        # infer school name by containment (NFC/NFD safe) without hard-coding sheet names
        matched_school = None
        for s in SCHOOLS:
            if _contains_all_tokens(sheet, [s]):
                matched_school = s
                break

        # if not matched, still keep but label as sheet (avoid crash)
        label = matched_school if matched_school else sheet

        df = _standardize_growth_df(raw)
        df["school"] = label
        out[label] = df

    return out


def _safe_concat(dfs: list[pd.DataFrame]) -> pd.DataFrame:
    dfs2 = [d for d in dfs if d is not None and not d.empty]
    if not dfs2:
        return pd.DataFrame()
    return pd.concat(dfs2, ignore_index=True)


def _plotly_layout(fig: go.Figure, title: str | None = None) -> go.Figure:
    fig.update_layout(
        title=title,
        font=dict(family=PLOTLY_FONT),
        legend_title_text="",
        margin=dict(l=20, r=20, t=60 if title else 30, b=20),
    )
    return fig


# =========================
# Load Data
# =========================
ROOT = Path(__file__).resolve().parent
DATA_DIR = ROOT / "data"

with st.spinner("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
    env_by_school = load_environment_data(str(DATA_DIR))
    growth_by_school = load_growth_data(str(DATA_DIR))

# Validate existence
env_all = _safe_concat([env_by_school.get(s, pd.DataFrame()) for s in SCHOOLS])
growth_all = _safe_concat([growth_by_school.get(s, pd.DataFrame()) for s in growth_by_school.keys()])

if env_all.empty:
    st.error("í™˜ê²½ ë°ì´í„°(CSV)ë¥¼ ì°¾ì§€ ëª»í–ˆê±°ë‚˜ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. data/ í´ë”ì™€ íŒŒì¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”.")
if not growth_by_school:
    st.error("ìƒìœ¡ ê²°ê³¼ ë°ì´í„°(XLSX)ë¥¼ ì°¾ì§€ ëª»í–ˆê±°ë‚˜ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. data/ í´ë”ì™€ íŒŒì¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”.")


# =========================
# Sidebar
# =========================
st.title("ğŸŒ± ê·¹ì§€ì‹ë¬¼ ìµœì  EC ë†ë„ ì—°êµ¬")

sel_school = st.sidebar.selectbox(
    "í•™êµ ì„ íƒ",
    ["ì „ì²´"] + SCHOOLS,
    index=0,
)

selected_schools = SCHOOLS if sel_school == "ì „ì²´" else [sel_school]


def get_selected_env() -> pd.DataFrame:
    return _safe_concat([env_by_school.get(s, pd.DataFrame()) for s in selected_schools])


def get_selected_growth() -> pd.DataFrame:
    # growth_by_school may include keys not exactly in SCHOOLS (if sheet names unmatched)
    # For comparison, prioritize exact school keys.
    dfs = []
    for s in selected_schools:
        if s in growth_by_school:
            dfs.append(growth_by_school[s])
    return _safe_concat(dfs)


# =========================
# Tabs
# =========================
tab1, tab2, tab3 = st.tabs(["ğŸ“– ì‹¤í—˜ ê°œìš”", "ğŸŒ¡ï¸ í™˜ê²½ ë°ì´í„°", "ğŸ“Š ìƒìœ¡ ê²°ê³¼"])

# -------------------------
# Tab 1: Overview
# -------------------------
with tab1:
    st.subheader("ì—°êµ¬ ë°°ê²½ ë° ëª©ì ")
    st.write(
        """
ë³¸ ëŒ€ì‹œë³´ë“œëŠ” 4ê°œ í•™êµì—ì„œ ì„œë¡œ ë‹¤ë¥¸ EC(ì „ê¸°ì „ë„ë„) ì¡°ê±´ìœ¼ë¡œ ê·¹ì§€ì‹ë¬¼ì„ ì¬ë°°í•œ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬,
(1) í•™êµë³„ í™˜ê²½(ì˜¨ë„/ìŠµë„/pH/EC) íŠ¹ì„±ì„ ë¹„êµí•˜ê³ , (2) EC ì¡°ê±´ë³„ ìƒìœ¡(ìƒì¤‘ëŸ‰/ì ìˆ˜/ê¸¸ì´)ì„ ì •ëŸ‰ ë¹„êµí•˜ì—¬,
(3) ìµœì  EC ë†ë„ë¥¼ ë„ì¶œí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.
"""
    )

    # School EC condition table (no sheet hard-coding, counts computed from loaded data)
    rows = []
    for s in SCHOOLS:
        # individuals count from growth data if available
        n = int(growth_by_school.get(s, pd.DataFrame()).shape[0]) if s in growth_by_school else 0
        rows.append(
            {
                "í•™êµëª…": s,
                "EC ëª©í‘œ": TARGET_EC.get(s, None),
                "ê°œì²´ìˆ˜": n,
                "ìƒ‰ìƒ": SCHOOL_COLOR.get(s, "#999999"),
            }
        )
    cond_df = pd.DataFrame(rows)

    st.markdown("#### í•™êµë³„ EC ì¡°ê±´")
    st.dataframe(cond_df, use_container_width=True, hide_index=True)

    # Key metrics cards (selected scope)
    env_sel = get_selected_env()
    growth_sel = get_selected_growth()

    total_n = int(growth_sel.shape[0]) if not growth_sel.empty else 0
    avg_temp = float(env_sel["temperature"].mean()) if not env_sel.empty else float("nan")
    avg_hum = float(env_sel["humidity"].mean()) if not env_sel.empty else float("nan")

    # Optimal EC inferred by max mean fresh weight by school(=EC)
    best_ec = None
    if not growth_all.empty:
        tmp = growth_all.copy()
        # keep only known schools for EC mapping
        tmp = tmp[tmp["school"].isin(SCHOOLS)]
        if not tmp.empty and "fresh_weight_g" in tmp.columns:
            mean_w = tmp.groupby("school", as_index=False)["fresh_weight_g"].mean()
            mean_w["target_ec"] = mean_w["school"].map(TARGET_EC)
            mean_w = mean_w.dropna(subset=["target_ec"])
            if not mean_w.empty:
                best_row = mean_w.sort_values("fresh_weight_g", ascending=False).iloc[0]
                best_ec = float(best_row["target_ec"])

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ì´ ê°œì²´ìˆ˜", f"{total_n:,}")
    c2.metric("í‰ê·  ì˜¨ë„(Â°C)", "-" if env_sel.empty else f"{avg_temp:.2f}")
    c3.metric("í‰ê·  ìŠµë„(%)", "-" if env_sel.empty else f"{avg_hum:.2f}")
    c4.metric("ë„ì¶œëœ ìµœì  EC", "-" if best_ec is None else f"{best_ec:.1f}")

# -------------------------
# Tab 2: Environment
# -------------------------
with tab2:
    st.subheader("í•™êµë³„ í™˜ê²½ ë°ì´í„° ë¹„êµ")

    env_sel = get_selected_env()

    if env_all.empty:
        st.error("í™˜ê²½ ë°ì´í„°ê°€ ì—†ì–´ ì‹œê°í™”ë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # Averages per school (use all schools for comparison, not only selection)
        env_cmp = env_all.copy()
        env_avg = (
            env_cmp.groupby("school", as_index=False)[["temperature", "humidity", "ph", "ec"]]
            .mean()
            .sort_values("school")
        )
        env_avg["target_ec"] = env_avg["school"].map(TARGET_EC)

        # 2x2 subplot
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=("í‰ê·  ì˜¨ë„", "í‰ê·  ìŠµë„", "í‰ê·  pH", "ëª©í‘œ EC vs ì‹¤ì¸¡ EC(í‰ê· )")
        )

        # (1) temp bar
        fig.add_trace(
            go.Bar(
                x=env_avg["school"],
                y=env_avg["temperature"],
                name="ì˜¨ë„",
            ),
            row=1, col=1
        )

        # (2) humidity bar
        fig.add_trace(
            go.Bar(
                x=env_avg["school"],
                y=env_avg["humidity"],
                name="ìŠµë„",
            ),
            row=1, col=2
        )

        # (3) pH bar
        fig.add_trace(
            go.Bar(
                x=env_avg["school"],
                y=env_avg["ph"],
                name="pH",
            ),
            row=2, col=1
        )

        # (4) target vs measured EC
        fig.add_trace(
            go.Bar(
                x=env_avg["school"],
                y=env_avg["target_ec"],
                name="ëª©í‘œ EC",
            ),
            row=2, col=2
        )
        fig.add_trace(
            go.Bar(
                x=env_avg["school"],
                y=env_avg["ec"],
                name="ì‹¤ì¸¡ EC(í‰ê· )",
            ),
            row=2, col=2
        )

        fig.update_layout(barmode="group")
        fig = _plotly_layout(fig, "í•™êµë³„ í™˜ê²½ í‰ê·  ë¹„êµ(2x2)")
        st.plotly_chart(fig, use_container_width=True)

        st.markdown("#### ì„ íƒí•œ í•™êµ ì‹œê³„ì—´")

        # time series charts: temperature, humidity, ec
        def _timeseries_fig(metric: str, title: str, add_target_ec: bool = False) -> go.Figure:
            base = env_all if sel_school == "ì „ì²´" else env_sel
            if base.empty:
                return go.Figure()

            fig_ts = go.Figure()
            for s in (SCHOOLS if sel_school == "ì „ì²´" else [sel_school]):
                d = env_by_school.get(s, pd.DataFrame())
                if d is None or d.empty:
                    continue
                fig_ts.add_trace(
                    go.Scatter(
                        x=d["time"],
                        y=d[metric],
                        mode="lines",
                        name=s,
                    )
                )

            if add_target_ec and sel_school != "ì „ì²´":
                t = TARGET_EC.get(sel_school, None)
                if t is not None:
                    fig_ts.add_hline(y=float(t), line_dash="dash", annotation_text="ëª©í‘œ EC", annotation_position="top left")

            fig_ts = _plotly_layout(fig_ts, title)
            fig_ts.update_xaxes(title_text="time")
            fig_ts.update_yaxes(title_text=metric)
            return fig_ts

        colA, colB, colC = st.columns(3)
        with colA:
            fig_t = _timeseries_fig("temperature", "ì˜¨ë„ ë³€í™”")
            if fig_t.data:
                st.plotly_chart(fig_t, use_container_width=True)
            else:
                st.error("ì„ íƒ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” ì˜¨ë„ ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        with colB:
            fig_h = _timeseries_fig("humidity", "ìŠµë„ ë³€í™”")
            if fig_h.data:
                st.plotly_chart(fig_h, use_container_width=True)
            else:
                st.error("ì„ íƒ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” ìŠµë„ ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        with colC:
            fig_e = _timeseries_fig("ec", "EC ë³€í™” (ëª©í‘œ EC ìˆ˜í‰ì„  í¬í•¨)", add_target_ec=True)
            if fig_e.data:
                st.plotly_chart(fig_e, use_container_width=True)
            else:
                st.error("ì„ íƒ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” EC ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        with st.expander("í™˜ê²½ ë°ì´í„° ì›ë³¸ í…Œì´ë¸” + CSV ë‹¤ìš´ë¡œë“œ"):
            show_df = env_sel if sel_school != "ì „ì²´" else env_all
            if show_df.empty:
                st.error("í‘œì‹œí•  í™˜ê²½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.dataframe(show_df.sort_values(["school", "time"]), use_container_width=True, hide_index=True)

                # CSV download (Bytes)
                csv_bytes = show_df.to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    label="CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv_bytes,
                    file_name="í™˜ê²½ë°ì´í„°_ì„ íƒë²”ìœ„.csv",
                    mime="text/csv",
                )

# -------------------------
# Tab 3: Growth
# -------------------------
with tab3:
    st.subheader("ECë³„ ìƒìœ¡ ê²°ê³¼ ë¹„êµ")

    if growth_all.empty:
        st.error("ìƒìœ¡ ê²°ê³¼ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # only known schools for EC mapping
        g = growth_all.copy()
        g = g[g["school"].isin(SCHOOLS)].copy()
        if g.empty:
            st.error("ìƒìœ¡ ê²°ê³¼ì—ì„œ í•™êµ ë§¤ì¹­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. XLSX ì‹œíŠ¸ëª…ì— í•™êµëª…ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        else:
            g["target_ec"] = g["school"].map(TARGET_EC)

            # Summary by EC (school)
            summary = (
                g.groupby(["school", "target_ec"], as_index=False)
                .agg(
                    mean_weight=("fresh_weight_g", "mean"),
                    mean_leaf=("leaf_count", "mean"),
                    mean_shoot=("shoot_len_mm", "mean"),
                    count=("id", "count"),
                )
                .sort_values("target_ec")
            )

            # Core result card: highlight max mean weight
            best = summary.sort_values("mean_weight", ascending=False).iloc[0]
            best_school = str(best["school"])
            best_ec_val = float(best["target_ec"])
            best_w = float(best["mean_weight"])

            # Emphasize í•˜ëŠ˜ê³ (EC 2.0) visually if it is best or expected
            note = "â­ ìµœëŒ“ê°’" if best_school == "í•˜ëŠ˜ê³ " else "ìµœëŒ“ê°’"
            st.markdown("### ğŸ¥‡ í•µì‹¬ ê²°ê³¼")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("ìµœëŒ€ í‰ê·  ìƒì¤‘ëŸ‰(EC)", f"{best_w:.3f} g", delta=f"{best_ec_val:.1f}")
            c2.metric("ìµœëŒ€ í‰ê·  ìƒì¤‘ëŸ‰ í•™êµ", best_school, delta=note)
            # show expected optimum
            exp_opt = TARGET_EC.get("í•˜ëŠ˜ê³ ", None)
            c3.metric("ê°€ì •/ì¡°ê±´ìƒ ìµœì  EC(í•˜ëŠ˜ê³ )", "-" if exp_opt is None else f"{exp_opt:.1f}")
            c4.metric("ë¶„ì„ í¬í•¨ ê°œì²´ìˆ˜(4ê°œêµ í•©)", f"{int(g.shape[0]):,}")

            # 2x2 bars: mean_weight, mean_leaf, mean_shoot, count
            fig2 = make_subplots(
                rows=2, cols=2,
                subplot_titles=("í‰ê·  ìƒì¤‘ëŸ‰(â­)", "í‰ê·  ì ìˆ˜", "í‰ê·  ì§€ìƒë¶€ ê¸¸ì´(mm)", "ê°œì²´ìˆ˜ ë¹„êµ")
            )

            fig2.add_trace(
                go.Bar(x=summary["target_ec"], y=summary["mean_weight"], name="í‰ê·  ìƒì¤‘ëŸ‰"),
                row=1, col=1
            )
            fig2.add_trace(
                go.Bar(x=summary["target_ec"], y=summary["mean_leaf"], name="í‰ê·  ì ìˆ˜"),
                row=1, col=2
            )
            fig2.add_trace(
                go.Bar(x=summary["target_ec"], y=summary["mean_shoot"], name="í‰ê·  ì§€ìƒë¶€ ê¸¸ì´"),
                row=2, col=1
            )
            fig2.add_trace(
                go.Bar(x=summary["target_ec"], y=summary["count"], name="ê°œì²´ìˆ˜"),
                row=2, col=2
            )

            # annotate best EC on mean_weight plot
            fig2.add_vline(
                x=best_ec_val,
                line_dash="dash",
                annotation_text="ìµœì (í‰ê·  ìƒì¤‘ëŸ‰ ìµœëŒ€)",
                annotation_position="top left",
                row=1, col=1
            )

            fig2.update_layout(barmode="group")
            fig2 = _plotly_layout(fig2, "ECë³„ ìƒìœ¡ ì§€í‘œ ë¹„êµ(2x2)")
            fig2.update_xaxes(title_text="EC", row=1, col=1)
            fig2.update_xaxes(title_text="EC", row=1, col=2)
            fig2.update_xaxes(title_text="EC", row=2, col=1)
            fig2.update_xaxes(title_text="EC", row=2, col=2)
            st.plotly_chart(fig2, use_container_width=True)

            st.markdown("#### í•™êµë³„ ìƒì¤‘ëŸ‰ ë¶„í¬")
            fig_box = px.box(
                g,
                x="school",
                y="fresh_weight_g",
                points="outliers",
                title="í•™êµë³„ ìƒì¤‘ëŸ‰ ë¶„í¬(ë°•ìŠ¤í”Œë¡¯)",
            )
            fig_box = _plotly_layout(fig_box)
            st.plotly_chart(fig_box, use_container_width=True)

            st.markdown("#### ìƒê´€ê´€ê³„ ë¶„ì„")
            cc1, cc2 = st.columns(2)

            with cc1:
                fig_sc1 = px.scatter(
                    g,
                    x="leaf_count",
                    y="fresh_weight_g",
                    color="school",
                    title="ì ìˆ˜ vs ìƒì¤‘ëŸ‰",
                )
                fig_sc1 = _plotly_layout(fig_sc1)
                st.plotly_chart(fig_sc1, use_container_width=True)

            with cc2:
                fig_sc2 = px.scatter(
                    g,
                    x="shoot_len_mm",
                    y="fresh_weight_g",
                    color="school",
                    title="ì§€ìƒë¶€ ê¸¸ì´ vs ìƒì¤‘ëŸ‰",
                )
                fig_sc2 = _plotly_layout(fig_sc2)
                st.plotly_chart(fig_sc2, use_container_width=True)

            with st.expander("í•™êµë³„ ìƒìœ¡ ë°ì´í„° ì›ë³¸ + XLSX ë‹¤ìš´ë¡œë“œ"):
                # show selected scope if requested
                g_sel = get_selected_growth()
                if sel_school == "ì „ì²´":
                    show_g = g.sort_values(["school", "id"])
                else:
                    show_g = g_sel.sort_values(["school", "id"]) if not g_sel.empty else pd.DataFrame()

                if show_g.empty:
                    st.error("í‘œì‹œí•  ìƒìœ¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ì„ íƒ í•™êµì˜ ì‹œíŠ¸ ë§¤ì¹­/ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”)")
                else:
                    st.dataframe(show_g, use_container_width=True, hide_index=True)

                # XLSX download (BytesIO) - multiple sheets (by school) for convenience
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                    if sel_school == "ì „ì²´":
                        # write each school sheet (only if exists)
                        for s in SCHOOLS:
                            df_s = g[g["school"] == s].copy()
                            if not df_s.empty:
                                df_s.to_excel(writer, index=False, sheet_name=s)
                    else:
                        df_s = show_g.copy()
                        # sheet name: selected school (safe)
                        df_s.to_excel(writer, index=False, sheet_name=sel_school)

                buffer.seek(0)
                st.download_button(
                    label="XLSX ë‹¤ìš´ë¡œë“œ",
                    data=buffer,
                    file_name="ìƒìœ¡ê²°ê³¼_ì„ íƒë²”ìœ„.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                )
